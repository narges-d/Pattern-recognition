# -*- coding: utf-8 -*-
"""LogisticRegressionFamilyExceptsoftmaxHomeWorkNumber1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kb0IN8O4sZy5moI8Ct8A9lYhi8d8yUHO
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import zscore
from sklearn.model_selection import train_test_split

from google.colab import drive
drive.mount('/content/drive/')

# Commented out IPython magic to ensure Python compatibility.
# Reading data and take feature and classes
# change directory to my drive

# %cd /content/drive/My Drive/

#read data text file and seprate it with tab and dont read header and name features f1 f2 .... f7 and label
data = pd.read_csv("HomeWork1.txt", sep="\t", header=None , names=["f1","f2","f3","f4","f5","f6","f7","label"])

# the number of features is m*n = shape which 1 means n means column - label
print("The number of features is",data.shape[1] - 1)
num_features=data.shape[1] - 1

# the number of classes is unique labels which is 123
print("The number of classsess is",len(data['label'].unique()))
num_classes=len(data['label'].unique())

# give rsult : Index(['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7'], dtype='object')
feature_columns = data.columns[:-1]

# Visulaizing data
# plot figure with height and width 12 inch

plt.figure(figsize=(12, 12))

# show index per f1 and f2 .... f7 without " "
# subplot in size of 7*7 = 49
# in the diagnol we plot histogram other wise we plot sactter feature i and feature j per two for i and j
for i, feature_x in enumerate(feature_columns):
  for j,feature_y in enumerate(feature_columns):
    plt.subplot(num_features,num_features, i * num_features + j + 1)
    if(i==j):
      plt.hist(data[feature_x],bins=20)
      plt.xlabel(feature_x)
      plt.ylabel("Frequency")
    else:
      plt.scatter(data[feature_x], data[feature_y], c=data[data.columns[-1]], cmap="viridis")
      plt.xlabel(feature_x)
      plt.ylabel(feature_y)

plt.tight_layout()
plt.show()

# zcore is method that calculate x- mean(meu)/varians
# np. where returns two list one is x dimension and second is y dimension of position what we want
# it doesnt matter we say len of index x or length of index y
z_scores = zscore(data[feature_columns])
outliers = np.where(np.abs(z_scores) > 2.75)
outliers_count = len(outliers[0])
print("Outliers count (threshold = 2.75):", outliers_count)

outliers_classes = data.iloc[outliers[0]][data.columns[-1]]
outliers_counts_by_class = outliers_classes.value_counts()
print("Outliers count by class (threshold = 2.75):\n", outliers_counts_by_class)

# try different threshhold
# by for in threshhold
thresholds = [1,2.5, 3.0,5]
for threshold in thresholds:
    outliers = np.where(np.abs(z_scores) > threshold)
    outliers_count = len(outliers[0])
    print("Outliers count (threshold =", threshold,"):",outliers_count)
# so the result is when we increase threshhold the number of outlinear reduce because we lower the presurre to select

"""Now look back at your plot from item 3, could you detect the outliers visually? Yes almost i can see the poitn which are far away from others but it depends on threshhold most of the times"""

# Split data per clasess for doing one vs one part of logistic regr
pd12 = data[data['label'] != 3]
pd13 = data[data['label'] != 2]
pd23 = data[data['label'] != 1]

class_mapping1 = {
    1: 1,
    2: 0
}

class_mapping2 = {
    1: 1,
    3: 0
}

class_mapping3 = {
    2: 1,
    3: 0
}

print("Dropping 3",pd12)
print("Drapping 2",pd13)
print("Drapping 1",pd23)

# Replace class numbers with new class numbers
pd12["label"] = pd12["label"].replace(class_mapping1)
pd13["label"] = pd13["label"].replace(class_mapping2)
pd23["label"] = pd23["label"].replace(class_mapping3)

print("Dropping 3",pd12)
print("Drapping 2",pd13)
print("Drapping 1",pd23)

x12 = pd12[['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7']]
y12 = pd12['label']

x13 = pd13[['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7']]
y13 = pd13['label']

x23 = pd23[['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7']]
y23 = pd23['label']

X_train_12, X_test_12, y_train_12, y_test_12 = train_test_split(x12, y12, test_size=0.25)
X_train_13, X_test_13, y_train_13, y_test_13 = train_test_split(x13, y13, test_size=0.25)
X_train_23, X_test_23, y_train_23, y_test_23 = train_test_split(x23, y23, test_size=0.25)

X_train_12  = X_train_12.values
X_test_12   = X_test_12.values
y_train_12  = y_train_12.values
y_test_12   = y_test_12.values

X_train_13  = X_train_13.values
X_test_13   = X_test_13.values
y_train_13  = y_train_13.values
y_test_13   = y_test_13.values

X_train_23  = X_train_23.values
X_test_23   = X_test_23.values
y_train_23  = y_train_23.values
y_test_23   = y_test_23.values


X_train_12 = np.c_[np.ones((len(X_train_12),1)),X_train_12]
X_test_12  = np.c_[np.ones((len(X_test_12),1)),X_test_12]

X_train_13 = np.c_[np.ones((len(X_train_13),1)),X_train_13]
X_test_13  = np.c_[np.ones((len(X_test_13),1)),X_test_13]

X_train_23 = np.c_[np.ones((len(X_train_23),1)),X_train_23]
X_test_23  = np.c_[np.ones((len(X_test_23),1)),X_test_23]

# Sigmoid function is a function which change the number into [0,1] is a balance sigmoid
# This is calculate the probability of x
# This is calculate of y predict whic mean teta * 1 + teta * x1 + teta * x2

def sigmoid(x):
  return (1 /(1 + np.exp(-x)))

# This is a function which just make and threshhold and separete data into 2 group

def predict(x,teta,threshhold=0.5):

  is_one= False

  probabilities=sigmoid(np.dot(x,teta))
  is_one=probabilities >= threshhold

  return is_one

# Accuracy sum 1 element for the matris predict commpared to threshhold where is it equal to y real
# At the last get mean of sum because we want % of totall and number between  and 1

def accuracy(x,y,teta):

  y_predict=predict(x,teta)
  return np.sum (y_predict == y) / len(y_predict)

def gradient_ascent(X, y, learning_rate, iteration):
    m, n  = X.shape
    theta = np.zeros(n)
    costs = []

    for i in range(iteration):

        h = sigmoid(np.dot(X,theta))
        gradient = np.dot(X.T,(y-h))/m
        theta += learning_rate * gradient

        cost = (-1/m)*(y.T @ np.log(h)+ (1-y).T @ np.log(1-h))
        costs.append(cost)
    return theta, costs

# Main impleent of ovo

teta_ovo=[]

# We have a list to append costs
cost_ovo=[]

iteration=1000
learning_rate=0.01

teta_12,cost_12 = gradient_ascent(X_train_12,y_train_12,learning_rate,iteration)
teta_ovo.append(teta_12)
cost_ovo.append(cost_12)
print("Stuation 1 tested with OVO method and result:")
print("Best cost:",cost_12[-1])
print("Answer iterartion is",len(cost_12))
print("Costs",cost_12)
print("teta",teta_12)
print()
print()

plt.plot(cost_12)
plt.xlabel("iteration")
plt.ylabel("cost function")
plt.title("cost function for 3 different way:")

teta_13,cost_13 = gradient_ascent(X_train_13,y_train_13,learning_rate,iteration)
teta_ovo.append(teta_13)
cost_ovo.append(cost_13)
print("Stuation 2 tested with OVO method and result:")
print("Best cost:",cost_13[-1])
print("Answer iterartion is",len(cost_13))
print("Costs",cost_13)
print("teta",teta_13)
print()
print()

plt.plot(cost_13)
plt.xlabel("iteration")
plt.ylabel("cost function")



teta_23,cost_23 = gradient_ascent(X_train_23,y_train_23,learning_rate,iteration)
teta_ovo.append(teta_23)
cost_ovo.append(cost_23)
print("Stuation 3 tested with OVO method and result:")
print("Best cost:",cost_23[-1])
print("Answer iterartion is",len(cost_23))
print("Costs",cost_23)
print("teta",teta_23)
print()
print()

plt.plot(cost_23)
plt.xlabel("iteration")
plt.ylabel("cost function")

y_predict_ova_12_test=predict(X_test_12,teta_12)
y_predict_ova_13_test=predict(X_test_13,teta_13)
y_predict_ova_23_test=predict(X_test_23,teta_23)

y_predict_ova_12_train=predict(X_train_12,teta_12)
y_predict_ova_13_train=predict(X_train_13,teta_13)
y_predict_ova_23_train=predict(X_train_23,teta_23)

accuracy_ova_12_test=( np.sum (y_predict_ova_12_test == y_test_12)) / len(y_test_12)
accuracy_ova_13_test=( np.sum (y_predict_ova_13_test == y_test_13)) / len(y_test_13)
accuracy_ova_23_test=( np.sum (y_predict_ova_23_test == y_test_23)) / len(y_test_23)

accuracy_ova_12_train=( np.sum (y_predict_ova_12_train == y_train_12)) / len(y_train_12)
accuracy_ova_13_train=( np.sum (y_predict_ova_13_train == y_train_13)) / len(y_train_13)
accuracy_ova_23_train=( np.sum (y_predict_ova_23_train == y_train_23)) / len(y_train_23)


print("Accuracy for test  data where we get class class 1 and 2:",accuracy_ova_12_test)
print()

print("Accuracy for test  data where we get class class 1 and 3:",accuracy_ova_13_test)
print()

print("Accuracy for test  data where we get class class 2 and 3:",accuracy_ova_23_test)
print()
######################################################################################
print("Accuracy for train  data where we get class class 1 and 2:",accuracy_ova_12_train)
print()

print("Accuracy for train  data where we get class class 1 and 3:",accuracy_ova_13_train)
print()

print("Accuracy for train  data where we get class class 2 and 3:",accuracy_ova_23_train)
print()



# Main of OVA implementation

# We have 3 set of teta for each time so we should have list
teta_ova=[]

# We have a list to append costs
cost_ova=[]

iteration=1000
learning_rate=0.01

#split data to 25 % test
X_train, X_test, y_train, y_test = train_test_split(data[feature_columns], data[data.columns[-1]], test_size=0.25, random_state=42)

X_train  = X_train.values
X_test   = X_test.values
y_train  = y_train.values
y_test   = y_test.values

X_train = np.c_[np.ones((len(X_train),1)),X_train]
X_test  = np.c_[np.ones((len(X_test),1)),X_test]

for i in range(num_classes):
  one_hot_classes = (y_train == i+1 ).astype(int)
  teta,cost = gradient_ascent(X_train,one_hot_classes,learning_rate,iteration)
  teta_ova.append(teta)
  cost_ova.append(cost)

  print("Class",i+1,"tested with OVA method and result:")
  print("Best cost:",cost[-1])
  print("Answer iterartion is",len(cost))
  print("Costs",cost)
  print("teta",teta)
  print()
  print()

  plt.plot(cost)
  plt.xlabel("iteration")
  plt.ylabel("cost function")
  plt.title("cost function for 3 different way to category class with train data")

# Call predit method to calculate y label based on tue and false
# I call both train data and test data for 3 way we have fixed now we have to compare them with real label and we ondo the O vs All method

y_predict_ova_test=[]
y_predict_ova_train=[]

for i in range(num_classes):
  y_predict_ova_test.append(predict(X_test,teta_ova[i]))
  y_predict_ova_train.append(predict(X_train,teta_ova[i]))

# Here we get one-hotter-vector for each class for y label and compare with the result
# Of y predict and calculate accuracy for 3 class and do the sae for train and test data

  for i in range(num_classes):
   y_real_onehot_train=(y_train == i+1).astype(int)
   y_real_onehot_test=(y_test == i+1).astype(int)

   accuracy_ova_train=( np.sum (y_predict_ova_train[i] == y_real_onehot_train)) / len(y_real_onehot_train)
   accuracy_ova_test= ( np.sum (y_predict_ova_test[i] == y_real_onehot_test)) / len(y_real_onehot_test)

   print("Accuracy for train data where we get class",i+1,"seperated and other are same ",accuracy_ova_train)
   print("Accuracy for test  data where we get class",i+1,"seperated and other are same ",accuracy_ova_test)
   print()

